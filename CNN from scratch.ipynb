{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data using PyTorch\n",
    "    1. extract-get the data from Fashion MNIST IMAGE DATA \n",
    "    2. Transform put the data in a tensor \n",
    "    3. Load- put the data into an object to make it accessible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this piece of code is unnecessary if we're using a  standard dataset already available in torchvision.datasets \n",
    "# but its a great example to show whats happening under the hood in pytorch\n",
    "# to create a dataset in pytorch we need to extend the torch.utils.data.Dataset class\n",
    "# and implement the following methods:\n",
    "\n",
    "class OHLC(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "    def __getitem__(self,index):\n",
    "        r = self.data.iloc[index]\n",
    "        label = torch.tensor(r.is_up_day, dtype=torch.long)\n",
    "        sample = self.normalize(torch.tensor([r.open, r.high, r.low, r.close]))\n",
    "        return sample,label\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "# we can create a dataset object by passing the csv file as an argument to the constructor\n",
    "# and then we can use the dataset object to create a dataloader object by passing it to the DataLoader class\n",
    "# and then we can use the dataloader object to iterate over the dataset in batches.\n",
    "# we can also use the dataloader object to get the number of samples in the dataset.\n",
    "# we can also use the dataloader object to get the number of batches in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [01:59<00:00, 221kB/s] \n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 235kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:19<00:00, 230kB/s] \n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 43.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# we're going to ETL the Fashion MNIST dataset\n",
    "\n",
    "train_set = datasets.FashionMNIST(\n",
    "    root=\"./data/FashionMNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()])\n",
    ")\n",
    "train_loader = DataLoader(train_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
