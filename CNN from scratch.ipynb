{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data using PyTorch\n",
    "    1. extract-get the data from Fashion MNIST IMAGE DATA \n",
    "    2. Transform put the data in a tensor \n",
    "    3. Load- put the data into an object to make it accessible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this piece of code is unnecessary if we're using a  standard dataset already available in torchvision.datasets \n",
    "# but its a great example to show whats happening under the hood in pytorch\n",
    "# to create a dataset in pytorch we need to extend the torch.utils.data.Dataset class\n",
    "# and implement the following methods:\n",
    "\n",
    "class OHLC(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "    def __getitem__(self,index):\n",
    "        r = self.data.iloc[index]\n",
    "        label = torch.tensor(r.is_up_day, dtype=torch.long)\n",
    "        sample = self.normalize(torch.tensor([r.open, r.high, r.low, r.close]))\n",
    "        return sample,label\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "# we can create a dataset object by passing the csv file as an argument to the constructor\n",
    "# and then we can use the dataset object to create a dataloader object by passing it to the DataLoader class\n",
    "# and then we can use the dataloader object to iterate over the dataset in batches.\n",
    "# we can also use the dataloader object to get the number of samples in the dataset.\n",
    "# we can also use the dataloader object to get the number of batches in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [01:20<00:00, 329kB/s] \n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 265kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:23<00:00, 188kB/s] \n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# we're going to ETL the Fashion MNIST dataset\n",
    "\n",
    "train_set = datasets.FashionMNIST(\n",
    "    root=\"./data/FashionMNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()])\n",
    ")\n",
    "train_loader = DataLoader(train_set,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in our case the dataset is balanced as the bins have equal number of samples\n",
    "# but if we encounter a case of unbalanced dataset then we can use oversampling and undersampling techniques and stratified sampling\n",
    "# we can also use a combination of these techniques to get a balanced dataset \n",
    "# it might be a burden on memory but it yields better resutls \n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "len(train_set)\n",
    "print(train_set.targets) # targets are the labels of the train data\n",
    "train_set.targets.bincount()\n",
    "# we can see that the bins are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regarding the paper \" A systematic study of the class imbalance problem in convolutional neural networks\" by\n",
    "https://arxiv.org/abs/1710.05381\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Accessing data in the training set\n",
    "# we use the python built in function iter(),which returns an object representing a stream of data.\n",
    "# The function next() takes this object and returns the next value from the stream.\n",
    "# We can use this to iterate over the data\n",
    "# we get 2 because the data is a tuple of 2 elements, a pair of image and its label\n",
    "\n",
    "sample = next(iter(train_set))\n",
    "print(len(sample))\n",
    "\n",
    "# we can destruct it or sequence unpacking \n",
    "image = sample[0]\n",
    "label = sample[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
